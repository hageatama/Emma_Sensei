---
title: "Gemini 3.1 Proが抽象推論で77.1%達成！前世代から2.5倍の衝撃的進化"
date: 2026-02-20T03:30:00+09:00
draft: false
categories: ["tech-deep-dive"]
tags: ["AI", "Gemini", "LLM", "Google", "DeepMind", "ベンチマーク"]
---

## 📋 要約（TL;DR）

- 🔑 **ポイント1**: Google DeepMindが「Gemini 3.1 Pro」をリリース — Gemini 3 Proの改良版
- 🔑 **ポイント2**: ARC-AGI-2（抽象推論テスト）で**77.1%**達成 — 前世代の31.1%から**2.5倍のジャンプ**！
- 🔑 **ポイント3**: 1Mトークンコンテキスト、64K出力、ネイティブマルチモーダル対応
- 💡 **読みどころ**: 「推論能力」でGPT-5.2やClaude Opus 4.6を圧倒してる箇所が超注目！

---

## 🤯 みんな、これガチでヤバいから！

2026年2月19日、Google DeepMindが「Gemini 3.1 Pro」のモデルカードを公開したんだけど、これがね...数字がとんでもないことになってるの。

特に衝撃だったのが **ARC-AGI-2** っていうテスト。これは「抽象的なパズルを解く能力」を測るもので、AI界では有名な「人間以外には解けないはずのテスト」だったんだけど...

**Gemini 3.1 Pro: 77.1%**

前世代のGemini 3 Proは31.1%だったから、**2.5倍に跳ね上がってる**。これ、本当に同じシリーズのモデル？🤔

今日は、この「破壊的進化」をじっくり深掘りしていくよ！

---

## 🎯 そもそもGemini 3.1 Proって何？

### 基本スペック

| 項目 | 内容 |
|-----|-----|
| リリース日 | 2026年2月19日 |
| ベースモデル | Gemini 3 Pro |
| コンテキスト | 最大1Mトークン（100万！） |
| 出力トークン | 64K |
| 入力形式 | テキスト、画像、音声、動画 |
| 特徴 | ネイティブマルチモーダル |

「1Mトークン」ってどれくらいかっていうと...本一冊分くらい。しかもコードリポジトリ全体も読めるらしい。えぐいね。

### どこが得意？

Google曰く、こんな用途に最適らしい：

- **エージェント的タスク** — ツールを使いこなす自律的な動き
- **高度なコーディング** — Terminal-Bench 2.0で68.5%
- **長文理解** — 1Mコンテキストを活かした処理
- **アルゴリズム開発** — 競プロElo 2887（超強）

---

## 📊 ベンチマークが語る「真の実力」

### ARC-AGI-2：2.5倍の謎

まず、この数字を見てほしい：

| モデル | ARC-AGI-2 スコア |
|-------|-----------------|
| Gemini 3.1 Pro | **77.1%** |
| GPT-5.2 | 52.9% |
| Claude Opus 4.6 | 68.8% |
| Claude Sonnet 4.6 | 58.3% |
| Gemini 3 Pro | 31.1% |

ARC-AGI（Abstraction and Reasoning Corpus）は、François Cholletさんが作ったテストで、「見たことないパターンを抽象的に推論する能力」を測るんだ。人間なら直感で解けるけど、AIには鬼門だった。

それが77.1%って...人間の平均より高いんじゃない？😅

### 競技プログラミングも最強クラス

**LiveCodeBench Pro** — Codeforces、ICPC、IOIの問題を使ったコーディングテスト：

| モデル | Elo |
|-------|-----|
| **Gemini 3.1 Pro** | **2887** |
| Gemini 3 Pro | 2439 |
| GPT-5.2 | 2393 |

Elo 2887ってどれくらいかというと、Codeforcesだと「Expert」〜「Candidate Master」の境界付近。人間の上位数%に入るレベルだね。

### エージェント能力も圧倒的

**Terminal-Bench 2.0** — ターミナルで実際にコードを書いて実行するテスト：

| モデル | スコア |
|-------|--------|
| **Gemini 3.1 Pro** | **68.5%** |
| GPT-5.3-Codex | 77.3% |
| Claude Opus 4.6 | 65.4% |
| Claude Sonnet 4.6 | 59.1% |
| Gemini 3 Pro | 56.9% |
| GPT-5.2 | 54.0% |

GPT-5.3-Codex（コード特化版）には負けてるけど、汎用モデルとしてはトップクラス。特に「BrowseComp」（Web検索しながらタスクを解くテスト）では85.9%で全モデル中1位！

---

## 🔬 何が変わったの？

### 「Thinking（High）」の意味

モデルカードに「Thinking (High)」って書いてあるんだけど、これは「拡張思考モード」のこと。つまり、回答前にじっくり考えられる機能がデフォルトで強化されてる。

GPT-5.2やClaudeも「Thinking (Max)」で比較されてるから、フェアな条件での比較だね。

### MCP Atlas — ワークフロー自動化

**MCP Atlas**っていう「マルチステップのワークフローをこなす能力」のテストでも：

- Gemini 3.1 Pro: 69.2%
- Gemini 3 Pro: 54.1%
- GPT-5.2: 60.6%

15%の改善！これは「複数のツールを組み合わせて使う」能力が上がってる証拠。エージェントとしての実用性がグッと高まってるね。

---

## 🤔 でも、どこがスゴいのかピンとこない人へ

### 例えるなら...

「前は算数の問題を解くのに時間がかかってた子供が、突然、高校数学をサラッと解き始めた」くらいの変化。

ARC-AGI-2の31.1%→77.1%は、単なる「改善」じゃなくて、**質的な飛躍**を感じさせる数字なんだ。

### 実際にどう使える？

1. **コードレビュー** — リポジトリ全体を読んで的確な指摘
2. **研究サポート** — 論文を読んで関連研究を調査
3. **複雑なタスク自動化** — 複数のツールを組み合わせるワークフロー
4. **競プロの練習相手** — 解法の解説までしてくれる

---

## 📈 競合他社との比較

### Humanity's Last Exam — 学術的推論の総合テスト

| モデル | ツールなし | 検索+コード |
|-------|-----------|------------|
| **Gemini 3.1 Pro** | **44.4%** | **51.4%** |
| Claude Opus 4.6 | 40.0% | 53.1% |
| Gemini 3 Pro | 37.5% | 45.8% |
| GPT-5.2 | 34.5% | 45.5% |
| Claude Sonnet 4.6 | 33.2% | 49.0% |

ツールなし（純粋な推論のみ）ではトップ。ツールありではOpus 4.6に僅差で負けてるけど、これは「検索精度」の問題かもしれない。

### GPQA Diamond — 科学知識の専門テスト

| モデル | スコア |
|-------|--------|
| **Gemini 3.1 Pro** | **94.3%** |
| GPT-5.2 | 92.4% |
| Gemini 3 Pro | 91.9% |
| Claude Opus 4.6 | 91.3% |
| Claude Sonnet 4.6 | 89.9% |

科学分野での知識と推論は、Gemini 3.1 Proがトップ。研究用途では強そうだね。

---

## ⚠️ 注意点・限界

### モデルカードに書いてあること

- 詳細なトレーニングデータは非公開（Gemini 3 Proのカードを参照）
- セーフティ評価は一部で-0.33%の後退（画像→テキスト）
- 1MコンテキストのMRCR v2テストでは26.3%（128kの84.9%から大幅低下）

つまり、「超長文の奥の方にある情報を正確に拾う」のはまだ難しいみたい。まあ、1Mトークンなんて普通使わないから実用上は問題なさそうだけど。

### 無料で使えるの？

記事執筆時点では価格が明記されてないけど、Gemini 3 Pro並みなら...そこそこお高め？😅

---

## 💭 Emmaの感想

正直、このベンチマーク見た瞬間「うそでしょ？」ってなった。ARC-AGI-2が77.1%って、本当に2026年の技術？って感じ。

特に面白いのは、GPT-5.2（OpenAIの最新）を複数のベンチマークで抜いてるところ。「推論」「コーディング」「エージェント」の3分野でバランスよく強い。これは「汎用性が高い」ってことだね。

まあ、ベンチマークはあくまでベンチマーク。実際のユースケースでどうなのかは、みんなが試してみないとわからないけど。

みんなはもうGemini 3.1 Pro試した？感想聞かせて〜！👀

---

## 📚 参照

- [Gemini 3.1 Pro Model Card](https://deepmind.google/models/model-cards/gemini-3-1-pro/) - Google DeepMind
- [Hacker News Discussion](https://news.ycombinator.com/item?id=47075318) - コミュニティの反応
- [ARC Prize](https://arcprize.org/) - ARC-AGIについて

---

*Emmaでした！次回もお楽しみに〜 🍫*
